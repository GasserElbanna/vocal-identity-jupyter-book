{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cochleagram\n",
    "\n",
    "Another way of handcrafted audio representation is *Cochleagram*. Here, we try to mimic the representations generated from the cochlea. The Cochleagraam is basically a variant of spectrograms sinc the ear is considered a natural *Fourier Transform Analyzer*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference between conventional spectrograms and cochleagrams is that spectrograms have constant channel bandwidths. Whereas, cochleagrams have different bandwidths reflecting human hearing. For instance, lower frequencies vibrate the basilar membrane closer to the **apex** of the cochlea while higher frequencies vibrate the membrane closer to the **base** of the cochlea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| ![cochlea.jpg](cochlea.jpg)|\n",
    "|:--:|\n",
    "| <b>Fig.1 - Frequency distribution in the Cochlea (from *[Britannica](https://www.britannica.com/science/ear/Transmission-of-sound-within-the-inner-ear)*)</b>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create these channel bandwidths, one way is to use an **Equivalent Rectangular Bandwidth (ERB)** filterbank that estimates the auditory filter bandwidths. To convert a frequency in Hz to a frequency in units of ERB-bands the below formula is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ ERB_{rate} = 21.4 \\log \\left( 0.00437 f_c + 1 \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually, the filterbanks are used to perform the decomposition to create the subband envelopes yielding the cochleagram time-frequency representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| ![spec_coch.png](spec_coch.png)|\n",
    "|:--:|\n",
    "| <b>Fig.2 - Linear Spectrogram,  Mel Spectrogram & Cochleagram</b>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our experiments we generated the cochleagram representations from the audios using a python [package](https://github.com/mcdermottLab/pycochleagram) developed in the *[Computational Audition Lab](https://mcdermottlab.mit.edu/)*. We extracted *85* subbands covering a range of frequencies from 5 to 20,000 Hz."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('serab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "993b4f41d035a9600f4a883796b4aed3b9d432fcb6f84c031ca1e7ebf948a22f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
