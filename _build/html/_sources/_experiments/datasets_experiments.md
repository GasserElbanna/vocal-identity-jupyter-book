# Datasets

In the upcoming analyses, we adopt the assumption that clustering one speaker utterances together (close distances) indicates a robust voice identity perception. That being said, we will examine different variations in voices (speaking style, emotions, accents and languages) and its effect on perturbing the identity clusters (distances) as a way of understanding the model's limitations and invariances.

The first set of experiments carried out investigates the robustness and sensititvity of BYOL-S model to cluster speaker identities with varying intrinsic and extrinsic speech setup (different speaking styles, accents, languages, emotions,..etc). In simple words, how would the model be affected if the speaker changed his/her speaking style? would it still identify the utterenaces to the same speaker?

That being said, several datasets were compiled to address different linguistic and paralinguistic variations between and within speakers.
