# Research Questions

The questions we try to address in this work is divided into three chapters. The first chapter elucidates the limitations and invariances of speech models for coding speaker identity. The second chapter explores the similarities and differences between models and humans in a voice discrimination task. Finally, the last chapter investigate the alignment between models' embeddings and brain representations.

### Questions:

1. Chapter 1 (Computational):
   1. What do speech self-supervised models encode?
   2. What are the models’ invariances and limitations in coding speaker identity?
2. Chapter 2 (Behavioral):
   1. How do these models discriminate between speaker identities compared to humans?
   2. What are the similarities/differences between models and humans perceptual spaces?
3. Chapter 3 (Neuroimaging):
   1. Can we map models’ speaker embeddings to brain activations?
   2. Is there a hierarchical model-brain correspondence for identity processing?

### Objectives:

1. Chapter 1 (Computational):
   1. Recruit a diverse set of models to be evaluated.
   2. Develop a pipeline to probe models’ encoding space.
   3. Run experiments with different intrinsic and extrinsic speaker variabilities.
2. Chapter 2 (Behavioral):
   1. Conduct a behavioral experiment studying speaker discrimination task.
   2. Benchmark the performance of models against human behavioral performance.
3. Chapter 3 (Neuroimaging):
   1. Use studyforrest dataset to examine model-brain similarities via linear encoding and alignment methods.
   2. Explore different brain regions that incorporate identity processing.